{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## get the data\n",
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file _concrete_data_week3.zip_ appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder _concrete_data_week3_ appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: _train_ and _valid_. And if you explore these folders, you will find that each contains two subfolders: _positive_ and _negative_. These are the same folders that we saw in the labs in the previous modules of this course, where _negative_ is the negative class and it represents the concrete images with no cracks and _positive_ is the positive class and it represents the concrete images with cracks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the _negative_ and _positive_ folders. This may consume all of your memory and you may end up with a **50\\*** error. So please **DO NOT DO IT**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1.  We are obviously dealing with two classes, so _num_classes_ is 2. \n",
    "2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3.  We will training and validating the model using batches of 100 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to _preprocess_input_ which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the _flow_from_directory_ method to get the training images as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the _flow_from_directory_ method to get the validation images and assign the result to **validation_generator**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click **here** for the solution.\n",
    "\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument _include_top_ and set it to **False**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 12s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the _layers_ attribute of our model object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.functional.Functional at 0x1d4ca8a6a20>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1d4cb0c07f0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1d4a251a748>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x1d4a25214e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4a2521668>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4a2521e10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4a2546c88>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x1d4a2529780>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1d4c7edd4e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c7eeac18>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c1315c88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c1308ba8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c13089b0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c7ef56a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c7ef5c18>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c7eea278>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c7ef5a58>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c7eea8d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8f07588>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c8f07a58>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c8f07080>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8f0c860>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8f245c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c8f24c88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8f24518>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8f4b5f8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c8f4bb70>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8f4b0f0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8f6d4e0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c8f6d6a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c8f6d828>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8f727b8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8f8c518>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c8f8cbe0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8f8c470>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8fac550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c8facac8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8fac048>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8fcd2b0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c8fcd898>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c8fcd780>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8feba90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c900a828>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c90107b8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9010978>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9029fd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c90306a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c8fd5710>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9030860>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c8feb470>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c904ce48>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c90524e0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c90523c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c905c2e8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9076198>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9076358>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c90765f8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9092b70>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9097588>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9097748>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c90afd30>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c90b63c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c90b62b0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c90c31d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c90d3f28>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c90da5f8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c90da7b8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c90f4da0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c90fb4e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c90fb6a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9115940>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c911b278>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c911b908>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9129128>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9139e48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c913d550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c913d710>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9159cf8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9160400>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c91605c0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c917dba8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c917df98>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9182f60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c91a33c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c91c0898>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c91c0f98>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c91c0da0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c91dfa20>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c91dff98>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c91970f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c91dff60>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c919cd68>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9202908>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c9202dd8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9202e48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9209c50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9223940>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9223ef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9223e48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9247978>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9247ef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9247eb8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9266860>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c9266cc0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9266358>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c926dda0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9289898>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9289f60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9289f28>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c92ac8d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c92ace48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c92ace10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c92ca7b8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c92cac88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c92ca2b0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c92d2cf8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c92ef7f0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c92efeb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c92efe80>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9311828>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9311da0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9311320>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9331710>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c9331be0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9331208>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9337c50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9354748>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9354e10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c93546a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9375780>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9375cf8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9375278>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c9396668>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c9396b38>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9396160>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c939aba8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c93b66a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c93b6d68>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c93b65f8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c93dc6d8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c93dcc50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c93dc1d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c93fc5c0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c93fca90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c93fc0b8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c941cc18>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c95689e8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c956d940>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c956db00>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c95902b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c9590828>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c9403898>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c95909e8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c941c5f8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4c95aa588>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4c95ad668>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4c95ad550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4c95b9470>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4ca7e0320>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4ca7e0898>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4ca7e0a58>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4ca802208>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4ca802780>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4ca802940>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4ca820f98>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4ca8265c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4ca8264a8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4ca82d3c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4ca847278>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4ca8477f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4ca8479b0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4ca862550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4ca86a6d8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d4ca86a898>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1d4ca884ef0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1d4ca88a518>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1d4ca88a400>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x1d4ca896320>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the _summary_ attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-172e67583a70>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/2\n",
      "301/301 [==============================] - 2143s 7s/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 2/2\n",
      "301/301 [==============================] - 2097s 7s/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0044 - val_accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file _classifier_resnet_model.h5_ apprear in the left directory pane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called _AI Capstone Project with Deep Learning_. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
    "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
    "| 2020-09-18        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright Â© 2020 [IBM Developer Skills Network](https://cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
